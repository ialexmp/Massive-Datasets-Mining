{"cells":[{"cell_type":"markdown","metadata":{"id":"zRPROV5GhWay"},"source":["# Practice Session 08: Data streams\n","\n","In this session we will take a large corpus of documents and compute some statistics using data streams methods.\n","\n","<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"]},{"cell_type":"markdown","metadata":{"id":"G2Es0nYdhXaU"},"source":["Author: <font color=\"blue\">Àlex Montoya Pérez</font>\n","\n","E-mail: <font color=\"blue\">alex.montoya.01@estudiant.upf.edu</font>\n","\n","Date: <font color=\"blue\">22/11/2023</font>"]},{"cell_type":"markdown","source":["# **Google Colaboratory Setup & Imports**\n","\n","In order to develop this laboratory, I used Google Colaboratory, since I have worked with different files I had to set up the environment as follows:\n","\n","\n","1.   Importing the drive module from the google.colab package.\n","2.   Mounting the Google Drive at the specified path (/content/drive).\n","3.   Changing the current working directory to the directory where I have all needed data /content/drive/MyDrive/MineriaDadesMasives/Labs/.\n","\n","Verify that we are in the correct directory:\n","\n","\n","4.   Printing the current working directory path using !pwd.\n","5.   Listing the contents of the current directory using !ls."],"metadata":{"id":"4ZtQxN_Wylcz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#Here is how to change current working directory\n","#By default the current working directory is /content\n","%cd /content/drive/MyDrive/MineriaDadesMasives/Labs/data/movie_dialog_corpus\n","#Print path and content of the current directory\n","!pwd\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-ZphnGlvIVG","executionInfo":{"status":"ok","timestamp":1700733762807,"user_tz":-60,"elapsed":2362,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"8e7ebe21-7b62-4987-9128-41809da6ab7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/MineriaDadesMasives/Labs/data/movie_dialog_corpus\n","/content/drive/MyDrive/MineriaDadesMasives/Labs/data/movie_dialog_corpus\n","movie_lines.tsv.gz  README.md\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FSSdXb9hWa6"},"outputs":[],"source":["import io\n","import nltk\n","import gzip\n","import random\n","import statistics\n","import secrets\n","import re\n","import gzip\n"]},{"cell_type":"markdown","metadata":{"id":"FLi-85aqhWa7"},"source":["# 0. Dataset and how to iterate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5yCU7cWhWa8"},"outputs":[],"source":["# Leave this code as-is\n","\n","INPUT_FILE = \"movie_lines.tsv.gz\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-C12cyLxhWa-"},"outputs":[],"source":["# Leave this code as-is\n","\n","# Producer in Python that reads a filename by words\n","def read_by_words(filename, max_words=-1, report_every=-1):\n","\n","    # Open the input file\n","    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n","\n","        # Initialize counter of words to stop at max_words\n","        counter = 0\n","\n","        # Regular expression to identify words having 3 letters or more and beginning with a-z\n","        word_expr = re.compile('^[a-z]{2,}$', re.IGNORECASE)\n","\n","        # Iterate through lines in the file\n","        for line in file:\n","\n","            elements = line.split(\"\\t\")\n","\n","            text = \"\"\n","            if len(elements) >= 5:\n","                text = elements[4].strip()\n","\n","            if counter > max_words and max_words != -1:\n","                break\n","\n","            for word in nltk.word_tokenize(text):\n","\n","                if word_expr.match(word):\n","                    counter += 1\n","\n","                    # Report\n","                    if (report_every != -1) and (counter % report_every == 0):\n","                        if max_words == -1:\n","                            print(\"- Read %d words so far\" % (counter))\n","                        else:\n","                            print(\"- Read %d/%d words so far\" % (counter, max_words))\n","\n","                    # Produce the word in lowercase\n","                    yield word.lower()"]},{"cell_type":"code","source":["nltk.download('punkt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zR941DGOldps","executionInfo":{"status":"ok","timestamp":1700733762809,"user_tz":-60,"elapsed":10,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"813c5ca2-322b-4b63-ba66-3760e5e2395d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jm6YBmD7hWa_","executionInfo":{"status":"ok","timestamp":1700733768851,"user_tz":-60,"elapsed":6049,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"6b33980c-fd4d-4ffd-ac4b-1afde5481c72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Current word 'image'\n","Current word 'this'\n","Current word 'you'\n","Current word 'up'\n","Current word 'it'\n","Current word 'did'\n","Current word 'who'\n","- Read 100000/300000 words so far\n","Current word 'around'\n","Current word 'something'\n","Current word 'fake'\n","Current word 'must'\n","Current word 'paint'\n","Current word 'do'\n","Current word 'same'\n","Current word 'it'\n","Current word 'you'\n","Current word 'fast'\n","- Read 200000/300000 words so far\n","Current word 'were'\n","Current word 'hospital'\n","Current word 'hall'\n","Current word 'it'\n","Current word 'hold'\n","Current word 'that'\n","Current word 'me'\n","Current word 'is'\n","Current word 'this'\n","Current word 'doctor'\n","Current word 'out'\n","Current word 'catchin'\n","Current word 'elizabeth'\n","Current word 'body'\n","- Read 300000/300000 words so far\n"]}],"source":["  # Leave this code as-is\n","\n","# Iterate through the file\n","for word in read_by_words(INPUT_FILE, max_words=300000, report_every=100000):\n","    # Prints 1/10000 of words\n","    if random.random() < 0.0001:\n","        print(\"Current word '%s'\" % (word))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvpwceKvhWbA"},"outputs":[],"source":["# Run this if above gives an error about 'punkt'\n","# nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"9Ex2otEUhWbB"},"source":["# 1. Determine approximately the top-10 words"]},{"cell_type":"markdown","source":["## Add Reservoir Function"],"metadata":{"id":"kYKCkX1Ul0Lj"}},{"cell_type":"code","source":["# adds an item to the reservoir, maintaining its size. If the reservoir is already of size max_size, a random item is selected and evicted before adding the item. It is important to evict an old item before adding the new item. Use the following skeleton:\n","\n","def add_to_reservoir(reservoir, item, max_reservoir_size):\n","    # If reservoir is not full, we just add the item\n","    if len(reservoir) < max_reservoir_size:\n","        reservoir.append(item)\n","    # If it's full, we discard randomly one item and put the new item there.\n","    else:\n","        random_index = random.randint(0, max_reservoir_size - 1)\n","        reservoir[random_index] = item\n","\n","    assert len(reservoir) <= max_reservoir_size\n"],"metadata":{"id":"3UIlntjZl6HD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reservoir Sampling"],"metadata":{"id":"xxZOOdP2nhTb"}},{"cell_type":"code","source":["#function to iterate through the file using the reservoir sampling method seen in class. In this function you will decide, for every item, whether to call add_to_reservoir or to ignore the item.\n","def reservoir_sampling(filename, reservoir_size, max_words=-1, report_every=-1):\n","    reservoir = []\n","    words_read = 0\n","\n","    for word in read_by_words(filename, max_words=max_words, report_every=report_every):\n","        words_read += 1\n","\n","        # If it's not full, call the function\n","        if len(reservoir) < reservoir_size:\n","            add_to_reservoir(reservoir, word, reservoir_size)\n","        else:\n","            # With probability 1 - s/n we ignore the item\n","            if random.random() < 1 - reservoir_size/words_read:\n","                continue\n","            # With probability s/n we add the item, discarding another item\n","            else:\n","                add_to_reservoir(reservoir, word, reservoir_size)\n","\n","    return (words_read, reservoir)\n"],"metadata":{"id":"mR4J0TW7nmD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cf0Ka_ThWbC","executionInfo":{"status":"ok","timestamp":1700733793347,"user_tz":-60,"elapsed":24512,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"ab9e6504-eb29-4882-d2fc-71efc4140072"},"outputs":[{"output_type":"stream","name":"stdout","text":["- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 1500\n"]}],"source":["# Leave this code as-is\n","\n","reservoir_size = 1500\n","(items_seen, reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=1000000, report_every=100000)\n","\n","print(\"Number of items seen    : %d\" % items_seen)\n","print(\"Number of items sampled : %d\" % len(reservoir) )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09yn0AW5hWbD","executionInfo":{"status":"ok","timestamp":1700733793348,"user_tz":-60,"elapsed":30,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"a54b9cd8-70ab-413d-c775-44e9e9c20e2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["89 you\n","43 the\n","35 to\n","32 it\n","28 that\n","28 do\n","24 and\n","21 of\n","19 we\n","18 what\n"]}],"source":["# Leave this code as-is\n","\n","freq = {}\n","for item in reservoir:\n","    freq[item] = reservoir.count(item)\n","\n","most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:10]\n","for absolute_frequency, word in most_frequent_items:\n","    print(\"%d %s\" % (absolute_frequency, word))"]},{"cell_type":"markdown","source":["## Top Items and their Relative Frequencies"],"metadata":{"id":"7N5f-5IxpMhf"}},{"cell_type":"code","source":["freq = {}\n","for item in reservoir:\n","    freq[item] = reservoir.count(item)\n","\n","# Sort items by absolute frequency in descending order and select the top 15\n","most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:15]\n","\n","# Print the 15 most frequent items and their relative frequencies as percentages\n","for absolute_frequency, word in most_frequent_items:\n","    # Calculate relative frequency as a percentage\n","    relative_frequency = (absolute_frequency / len(reservoir)) * 100\n","    # Print the result\n","    print(\"%.2f%%\" % relative_frequency, word)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLBHimx1pFH1","executionInfo":{"status":"ok","timestamp":1700733793618,"user_tz":-60,"elapsed":297,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"cc7a4c66-2fb2-44b7-a34e-8e215c19e45a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5.93% you\n","2.87% the\n","2.33% to\n","2.13% it\n","1.87% that\n","1.87% do\n","1.60% and\n","1.40% of\n","1.27% we\n","1.20% what\n","1.20% is\n","1.13% in\n","1.13% he\n","0.93% my\n","0.93% for\n"]}]},{"cell_type":"markdown","source":["## Estimate for the relative and absolute frequency of the words in the entire dataset."],"metadata":{"id":"FTR114jFtjsH"}},{"cell_type":"code","source":["# Increase the max limit of words so that one pass takes no more than 5 minutes to be completed. Replace this cell with your code to try different reservoir sizes. In each case, print your estimate for the relative and absolute frequency of the words in the entire dataset.\n","def calculate_frequencies(reservoir):\n","    freq = {}\n","    for item in reservoir:\n","        freq[item] = freq.get(item, 0) + 1\n","    return freq\n","\n","def print_top_words(reservoir_size, max_words=1000000, report_every=100000):\n","    print(\"Reservoir size:\", reservoir_size, \"\\n\")\n","\n","    items_seen, reservoir = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=max_words, report_every=report_every)\n","    print(\"Number of items seen    : %d\" % items_seen)\n","    print(\"Number of items sampled : %d\" % len(reservoir))\n","\n","    freq = calculate_frequencies(reservoir)\n","\n","    most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n","    for absolute_frequency, word in most_frequent_items:\n","        relative_frequency = absolute_frequency / len(reservoir)\n","        print(\"Absolute freq: %d, Relative freq: %f, word: %s\" % (absolute_frequency, relative_frequency, word))\n"],"metadata":{"id":"ApYf4Pk1qfLq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test different reservoir sizes [100, 500, 3000]"],"metadata":{"id":"7bL4sqWit2Sz"}},{"cell_type":"code","source":["# Reservoir Size = 100\n","print_top_words(100)\n","print(\"\\n\")\n","\n","# Reservoir Size = 500\n","print_top_words(500)\n","print(\"\\n\")\n","\n","# Reservoir Size = 3000\n","print_top_words(3000)\n","print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7P7XgJhHuQdl","executionInfo":{"status":"ok","timestamp":1700733866713,"user_tz":-60,"elapsed":73099,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"90cec60e-8efe-4c0c-ac46-daa07ed914b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reservoir size: 100 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 100\n","Absolute freq: 7, Relative freq: 0.070000, word: you\n","Absolute freq: 3, Relative freq: 0.030000, word: just\n","Absolute freq: 3, Relative freq: 0.030000, word: did\n","Absolute freq: 3, Relative freq: 0.030000, word: and\n","Absolute freq: 2, Relative freq: 0.020000, word: what\n","\n","\n","Reservoir size: 500 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 500\n","Absolute freq: 18, Relative freq: 0.036000, word: you\n","Absolute freq: 18, Relative freq: 0.036000, word: the\n","Absolute freq: 17, Relative freq: 0.034000, word: to\n","Absolute freq: 15, Relative freq: 0.030000, word: it\n","Absolute freq: 13, Relative freq: 0.026000, word: that\n","\n","\n","Reservoir size: 3000 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 3000\n","Absolute freq: 147, Relative freq: 0.049000, word: you\n","Absolute freq: 102, Relative freq: 0.034000, word: the\n","Absolute freq: 76, Relative freq: 0.025333, word: to\n","Absolute freq: 54, Relative freq: 0.018000, word: it\n","Absolute freq: 50, Relative freq: 0.016667, word: that\n","\n","\n"]}]},{"cell_type":"markdown","source":["## Min Reservoir size to have stable results"],"metadata":{"id":"yyzoAJ9bwLJu"}},{"cell_type":"code","source":["#Find by trial and error, and include in your report, the minimum reservoir size you need to have somewhat stable results (e.g., the same top-3 words in two consecutive runs of the algorithm).\n","\n","# Reservoir Size = 1000\n","print_top_words(1000)\n","print(\"\\n\")\n","\n","# Reservoir Size = 1500\n","print_top_words(1500)\n","print(\"\\n\")\n","\n","# Reservoir Size = 5000\n","print_top_words(5000)\n","print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjkU32aSu226","executionInfo":{"status":"ok","timestamp":1700733941607,"user_tz":-60,"elapsed":74908,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"b12b228f-b40c-42d7-8ff7-343dd5c45cd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reservoir size: 1000 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 1000\n","Absolute freq: 55, Relative freq: 0.055000, word: you\n","Absolute freq: 35, Relative freq: 0.035000, word: to\n","Absolute freq: 30, Relative freq: 0.030000, word: that\n","Absolute freq: 21, Relative freq: 0.021000, word: the\n","Absolute freq: 21, Relative freq: 0.021000, word: it\n","\n","\n","Reservoir size: 1500 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 1500\n","Absolute freq: 82, Relative freq: 0.054667, word: you\n","Absolute freq: 55, Relative freq: 0.036667, word: the\n","Absolute freq: 41, Relative freq: 0.027333, word: to\n","Absolute freq: 35, Relative freq: 0.023333, word: it\n","Absolute freq: 31, Relative freq: 0.020667, word: and\n","\n","\n","Reservoir size: 5000 \n","\n","- Read 100000/1000000 words so far\n","- Read 200000/1000000 words so far\n","- Read 300000/1000000 words so far\n","- Read 400000/1000000 words so far\n","- Read 500000/1000000 words so far\n","- Read 600000/1000000 words so far\n","- Read 700000/1000000 words so far\n","- Read 800000/1000000 words so far\n","- Read 900000/1000000 words so far\n","- Read 1000000/1000000 words so far\n","Number of items seen    : 1000028\n","Number of items sampled : 5000\n","Absolute freq: 245, Relative freq: 0.049000, word: you\n","Absolute freq: 169, Relative freq: 0.033800, word: the\n","Absolute freq: 147, Relative freq: 0.029400, word: to\n","Absolute freq: 95, Relative freq: 0.019000, word: it\n","Absolute freq: 88, Relative freq: 0.017600, word: do\n","\n","\n"]}]},{"cell_type":"markdown","source":["Examining the output above reveals distinct top three words when reservoir_size is set to 1000 compared to 1500, but interestingly, the results align with reservoir_size = 5000. This suggests that 5000 might be the optimal minimum reservoir size. While some runs with reservoir_size = 1000 did yield the same three words, the consistency was not as pronounced as with reservoir_size = 1500. Therefore, based on these observations, I would recommend utilizing reservoir_size = 1500."],"metadata":{"id":"8qdFMnCUxWt2"}},{"cell_type":"markdown","metadata":{"id":"ialCOs9KhWbF"},"source":["# 2. Determine approximately the distinct number of words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LCZKAFhhWbF"},"outputs":[],"source":["# Leave this code as-is\n","\n","def count_trailing_zeroes(number):\n","    count = 0\n","    while number & 1 == 0:\n","        count += 1\n","        number = number >> 1\n","    return count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wH2XMwY5hWbG"},"outputs":[],"source":["# Leave this code as-is\n","\n","def random_hash_function():\n","    # We use a cryptographically safe generator for the salt of our hash function\n","    salt = secrets.token_bytes(32)\n","    return lambda string: hash(string + str(salt))"]},{"cell_type":"markdown","source":["## Perform Requested number of passes"],"metadata":{"id":"KjD4oIujs5Ni"}},{"cell_type":"code","source":["# Function to perform the probabilistic counting and return the estimate\n","def perform_probabilistic_counting(num_passes, max_words=None):\n","    estimates = []\n","\n","    for i in range(num_passes):\n","        hash_function = random_hash_function()\n","        R = []\n","        for word in read_by_words(INPUT_FILE, max_words=max_words, report_every=-1):\n","            hash_value = hash_function(word)\n","            R.append(count_trailing_zeroes(hash_value))\n","        estimate = 2 ** max(R)\n","        estimates.append(estimate)\n","        print(\"Estimate on pass %d: %d distinct words\" % (i + 1, estimate))\n","\n","    return estimates\n","\n","number_of_passes = 5\n","estimates_5_passes = perform_probabilistic_counting(number_of_passes, max_words=1000000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luNM7NAytBnN","executionInfo":{"status":"ok","timestamp":1700735367360,"user_tz":-60,"elapsed":125489,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"5c18027e-88ee-4194-84e8-ee45e30a023a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Estimate on pass 1: 16384 distinct words\n","Estimate on pass 2: 16384 distinct words\n","Estimate on pass 3: 65536 distinct words\n","Estimate on pass 4: 131072 distinct words\n","Estimate on pass 5: 262144 distinct words\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vOeInSEhWbG","executionInfo":{"status":"ok","timestamp":1700735433903,"user_tz":-60,"elapsed":269,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75f98305-aa69-4b93-b0c8-47814b3bec80"},"outputs":[{"output_type":"stream","name":"stdout","text":["* Average of estimates: 98304.0\n","* Median  of estimates: 65536.0\n"]}],"source":["# Leave this code as-is\n","\n","print(\"* Average of estimates: %.1f\" % statistics.mean(estimates_5_passes))\n","print(\"* Median  of estimates: %.1f\" % statistics.median(estimates_5_passes))"]},{"cell_type":"markdown","source":["## Comparing Algorithm Performance with 10 Passes vs. 20 Passes in Triple Runs"],"metadata":{"id":"CCoX-6mst-Wr"}},{"cell_type":"code","source":["# Perform 3 separate runs with 10 passes each\n","for run in range(3):\n","    print(f\"\\nRun {run + 1} (10 passes):\")\n","    estimates_10_passes = perform_probabilistic_counting(num_passes=10, max_words=1000000)\n","    print(f\"Median of estimates: {statistics.median(estimates_10_passes)}\")\n","    print(f\"Average of estimates: {statistics.mean(estimates_10_passes)}\")\n","\n","# Perform 3 separate runs with 20 passes each\n","for run in range(3):\n","    print(f\"\\nRun {run + 1} (20 passes):\")\n","    estimates_20_passes = perform_probabilistic_counting(num_passes=20, max_words=1000000)\n","    print(f\"Median of estimates: {statistics.median(estimates_20_passes)}\")\n","    print(f\"Average of estimates: {statistics.mean(estimates_20_passes)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phe9oApMrFcq","executionInfo":{"status":"ok","timestamp":1700737790790,"user_tz":-60,"elapsed":2279097,"user":{"displayName":"ÀLEX MONTOYA PÉREZ","userId":"15889589265134071867"}},"outputId":"7b6d18a1-6a09-4777-9fa5-479aea77ec51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Run 1 (10 passes):\n","Estimate on pass 1: 16384 distinct words\n","Estimate on pass 2: 32768 distinct words\n","Estimate on pass 3: 4194304 distinct words\n","Estimate on pass 4: 4096 distinct words\n","Estimate on pass 5: 16384 distinct words\n","Estimate on pass 6: 16384 distinct words\n","Estimate on pass 7: 16384 distinct words\n","Estimate on pass 8: 8192 distinct words\n","Estimate on pass 9: 65536 distinct words\n","Estimate on pass 10: 16384 distinct words\n","Median of estimates: 16384.0\n","Average of estimates: 438681.6\n","\n","Run 2 (10 passes):\n","Estimate on pass 1: 16384 distinct words\n","Estimate on pass 2: 32768 distinct words\n","Estimate on pass 3: 32768 distinct words\n","Estimate on pass 4: 32768 distinct words\n","Estimate on pass 5: 32768 distinct words\n","Estimate on pass 6: 16384 distinct words\n","Estimate on pass 7: 16384 distinct words\n","Estimate on pass 8: 8192 distinct words\n","Estimate on pass 9: 8192 distinct words\n","Estimate on pass 10: 32768 distinct words\n","Median of estimates: 24576.0\n","Average of estimates: 22937.6\n","\n","Run 3 (10 passes):\n","Estimate on pass 1: 16384 distinct words\n","Estimate on pass 2: 131072 distinct words\n","Estimate on pass 3: 8192 distinct words\n","Estimate on pass 4: 32768 distinct words\n","Estimate on pass 5: 32768 distinct words\n","Estimate on pass 6: 8192 distinct words\n","Estimate on pass 7: 65536 distinct words\n","Estimate on pass 8: 65536 distinct words\n","Estimate on pass 9: 16384 distinct words\n","Estimate on pass 10: 32768 distinct words\n","Median of estimates: 32768.0\n","Average of estimates: 40960\n","\n","Run 1 (20 passes):\n","Estimate on pass 1: 32768 distinct words\n","Estimate on pass 2: 65536 distinct words\n","Estimate on pass 3: 16384 distinct words\n","Estimate on pass 4: 131072 distinct words\n","Estimate on pass 5: 16384 distinct words\n","Estimate on pass 6: 65536 distinct words\n","Estimate on pass 7: 32768 distinct words\n","Estimate on pass 8: 16384 distinct words\n","Estimate on pass 9: 1048576 distinct words\n","Estimate on pass 10: 16384 distinct words\n","Estimate on pass 11: 32768 distinct words\n","Estimate on pass 12: 16384 distinct words\n","Estimate on pass 13: 32768 distinct words\n","Estimate on pass 14: 8192 distinct words\n","Estimate on pass 15: 32768 distinct words\n","Estimate on pass 16: 65536 distinct words\n","Estimate on pass 17: 65536 distinct words\n","Estimate on pass 18: 16384 distinct words\n","Estimate on pass 19: 65536 distinct words\n","Estimate on pass 20: 8192 distinct words\n","Median of estimates: 32768.0\n","Average of estimates: 89292.8\n","\n","Run 2 (20 passes):\n","Estimate on pass 1: 32768 distinct words\n","Estimate on pass 2: 16384 distinct words\n","Estimate on pass 3: 262144 distinct words\n","Estimate on pass 4: 16384 distinct words\n","Estimate on pass 5: 8192 distinct words\n","Estimate on pass 6: 8192 distinct words\n","Estimate on pass 7: 32768 distinct words\n","Estimate on pass 8: 8192 distinct words\n","Estimate on pass 9: 32768 distinct words\n","Estimate on pass 10: 16384 distinct words\n","Estimate on pass 11: 32768 distinct words\n","Estimate on pass 12: 8192 distinct words\n","Estimate on pass 13: 8192 distinct words\n","Estimate on pass 14: 8192 distinct words\n","Estimate on pass 15: 1048576 distinct words\n","Estimate on pass 16: 65536 distinct words\n","Estimate on pass 17: 8192 distinct words\n","Estimate on pass 18: 32768 distinct words\n","Estimate on pass 19: 8192 distinct words\n","Estimate on pass 20: 262144 distinct words\n","Median of estimates: 16384.0\n","Average of estimates: 95846.4\n","\n","Run 3 (20 passes):\n","Estimate on pass 1: 32768 distinct words\n","Estimate on pass 2: 32768 distinct words\n","Estimate on pass 3: 16384 distinct words\n","Estimate on pass 4: 131072 distinct words\n","Estimate on pass 5: 8192 distinct words\n","Estimate on pass 6: 16384 distinct words\n","Estimate on pass 7: 32768 distinct words\n","Estimate on pass 8: 8192 distinct words\n","Estimate on pass 9: 16384 distinct words\n","Estimate on pass 10: 32768 distinct words\n","Estimate on pass 11: 65536 distinct words\n","Estimate on pass 12: 8192 distinct words\n","Estimate on pass 13: 131072 distinct words\n","Estimate on pass 14: 16384 distinct words\n","Estimate on pass 15: 16384 distinct words\n","Estimate on pass 16: 65536 distinct words\n","Estimate on pass 17: 32768 distinct words\n","Estimate on pass 18: 16384 distinct words\n","Estimate on pass 19: 32768 distinct words\n","Estimate on pass 20: 16384 distinct words\n","Median of estimates: 24576.0\n","Average of estimates: 36454.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"1t9ULx7shWbN"},"source":["<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}